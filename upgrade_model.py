import torch
import os
import shutil
from spirecomm.utils.path import get_root_dir

# æŒ‡å®šè¦ä¿®å¤çš„æ–‡ä»¶ (é€šå¸¸æ˜¯ latest.pth)
TARGET_FILENAME = "step_670000.pth"

def fix_global_numeric_dim():
    models_dir = os.path.join(get_root_dir(), "models")
    path = os.path.join(models_dir, TARGET_FILENAME)
    
    if not os.path.exists(path):
        print(f"âŒ æ‰¾ä¸åˆ°æ–‡ä»¶: {path}")
        return

    print(f"ğŸ”§ æ­£åœ¨æ£€æŸ¥: {path} ...")
    
    # åŠ è½½
    checkpoint = torch.load(path, map_location='cpu', weights_only=False)
    state_dict = checkpoint['model']

    # ç›®æ ‡å±‚ï¼šå…¨å±€æ•°å€¼ç¼–ç å±‚
    key = "global_num_enc.weight"
    
    if key not in state_dict:
        print(f"âŒ æ‰¾ä¸åˆ°å±‚: {key}")
        return

    old_weight = state_dict[key] # åº”è¯¥æ˜¯ [128, 17]
    out_dim, in_dim = old_weight.shape
    
    print(f"   å½“å‰ç»´åº¦: {old_weight.shape}")

    if in_dim == 18:
        print("âœ… æ­¤æ–‡ä»¶å·²ç»æ˜¯ 18 ç»´äº†ï¼Œæ— éœ€ä¿®å¤ï¼")
        return
    elif in_dim == 17:
        print("âš¡ æ£€æµ‹åˆ°æ—§ç»´åº¦ (17)ï¼Œå¼€å§‹æ‰©å®¹åˆ° 18...")
        
        # è®¡ç®—å·®å€¼ (1)
        diff = 18 - 17
        
        # ç”Ÿæˆéšæœºå™ªå£°æƒé‡ (1åˆ—)
        extension = torch.randn(out_dim, diff) * 0.01
        
        # æ‹¼æ¥ï¼š[æ—§æƒé‡, æ–°æƒé‡] -> [128, 18]
        new_weight = torch.cat([old_weight, extension], dim=1)
        
        # æ›¿æ¢å›å»
        state_dict[key] = new_weight
        checkpoint['model'] = state_dict
        
        # å¤‡ä»½å¹¶è¦†ç›–
        shutil.copyfile(path, path + ".bak_17")
        torch.save(checkpoint, path)
        
        print(f"âœ… ä¿®å¤å®Œæˆï¼æ–°ç»´åº¦: {new_weight.shape}")
        print("ğŸš€ ç°åœ¨å¯ä»¥é‡æ–°å¯åŠ¨ Evaluator/Trainer äº†ï¼")
        
    else:
        print(f"âŒ æœªçŸ¥ç»´åº¦ {in_dim}ï¼Œæœªåšå¤„ç†ã€‚")

if __name__ == "__main__":
    fix_global_numeric_dim()